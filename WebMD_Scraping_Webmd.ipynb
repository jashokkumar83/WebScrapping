{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcVPDyymwuA0"
      },
      "source": [
        "#############################\n",
        "############################# MULTIPLE PAGES ###############\n",
        "############################################################\n",
        "\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import csv\n",
        "\n",
        "\n",
        "x0 = []\n",
        "x1 = []\n",
        "x2 = []\n",
        "x3 = []\n",
        "x4 = []\n",
        "x5 = []\n",
        "x6 = []\n",
        "x7 = []\n",
        "\n",
        "for i in range(1,5):\n",
        "    url = 'https://www.webmd.com/drugs/drugreview-64439-abilify-oral?conditionid=&sortval=1&pagenumber=2'\n",
        "    #url = 'https://www.webmd.com/drugs/drugreview-63990-Lexapro+oral.aspx?drugid=63990&drugname=Lexapro+oral&pageIndex=1&sortby=3&conditionFilter=-500'.format(i)\n",
        "    #url = 'https://www.webmd.com/drugs/drugreview-63990-Lexapro+oral.aspx?drugid=63990&drugname=Lexapro+oral&pageIndex={}&sortby=3&conditionFilter=-1'.format(i)\n",
        "    #req = Request(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    req = Request(url+str(i),headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    webpage = urlopen(req).read()\n",
        "    soup = BeautifulSoup(webpage, \"html.parser\")\n",
        "\n",
        "    ##### ********* Condition Information *****\n",
        "\n",
        "    required0 = soup.find_all(\"div\", {\"class\":\"date\"})\n",
        "    x00 = []\n",
        "    for i in required0:\n",
        "        x00.append(i.get_text())\n",
        "\n",
        "\n",
        "    for i in x00:\n",
        "        xee = i.replace('\\t', '').replace('\\r','').replace('\\n','')\n",
        "        x0.append(xee)\n",
        "\n",
        "\n",
        "    ########## name, age, gender, medication, patient type\n",
        "\n",
        "    x01 = []\n",
        "\n",
        "    required = soup.find_all(\"div\", {\"class\": \"card-header\"})\n",
        "    for i in required:\n",
        "        x01.append(i.get_text())\n",
        "\n",
        "\n",
        "    for i in x01:\n",
        "        xee1 = i.replace('\\t', '').replace('\\r','').replace('\\n','')\n",
        "        x1.append(xee1)\n",
        "\n",
        "\n",
        "    ################### condition\n",
        "\n",
        "    x02 = []\n",
        "\n",
        "    for strong_tag in soup.find_all(\"strong\", {\"class\": \"condition\"}):\n",
        "        x02.append(strong_tag.text)\n",
        "\n",
        "\n",
        "    for i in x02:\n",
        "        xee2 = i.replace('\\t', '').replace('\\r','').replace('\\n','')\n",
        "        x2.append(xee2)\n",
        "\n",
        "\n",
        "    ################## Description\n",
        "\n",
        "    required3 = soup.find_all(\"div\", {\"class\": \"review-details\"})\n",
        "\n",
        "    x03 = []\n",
        "\n",
        "    for i in required3:\n",
        "        try:\n",
        "            #i1==i.soup.find(\"p\", {\"class\": \"description\"})\n",
        "            x32 = (i.find('p', {'class':'description-text'}).text)\n",
        "            x03.append(x32)\n",
        "        except:\n",
        "            x03.append(\"None\")\n",
        "\n",
        "\n",
        "    for i in x03:\n",
        "        xee2 = i.replace('\\t', '').replace('\\r','').replace('\\n','')\n",
        "        x3.append(xee2)\n",
        "\n",
        "\n",
        "    ############## overall-rating\n",
        "\n",
        "    x04 = []\n",
        "\n",
        "    required = soup.find_all(\"div\", {\"class\": \"overall-rating\"})\n",
        "    for i in required:\n",
        "        x04.append(i.get_text())\n",
        "\n",
        "\n",
        "    for i in x04:\n",
        "        xee3 = i.replace('\\t', '').replace('\\r','').replace('\\n','')\n",
        "        x4.append(xee3)\n",
        "\n",
        "    ################# Effectiveness, Ease of Use, Satisfaction\n",
        "\n",
        "    required5 = soup.find_all(\"div\", {\"class\": \"categories\"})\n",
        "\n",
        "    x05 = []\n",
        "\n",
        "    for i in required5:\n",
        "        for strong_tag in i:\n",
        "            x05.append(strong_tag.text)\n",
        "\n",
        "\n",
        "    x06 = []\n",
        "\n",
        "    for i in required5:\n",
        "        sources=i.find_all('div',{\"aria-valuenow\":True})\n",
        "        for source in sources:\n",
        "            x06.append(source['aria-valuenow'])\n",
        "\n",
        "    x07 = []\n",
        "\n",
        "    for i, j in zip(x05,x06):\n",
        "        a1 = \" : \".join([i,j])\n",
        "        x07.append(a1)\n",
        "\n",
        "    x08 = x07[0::3]\n",
        "    x09 = x07[1::3]\n",
        "    x10 = x07[2::3]\n",
        "\n",
        "    for i in x08:\n",
        "        x5.append(i)\n",
        "    for i in x09:\n",
        "        x6.append(i)\n",
        "    for i in x10:\n",
        "        x7.append(i)\n",
        "\n",
        "\n",
        "rows = list(zip(x0, x1, x2, x3, x4, x5, x6, x7))\n",
        "\n",
        "with open('Abilify Oral.csv', 'w', encoding='utf-8', newline='') as myFile:\n",
        "    writer = csv.writer(myFile)\n",
        "    writer.writerows(rows)"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}